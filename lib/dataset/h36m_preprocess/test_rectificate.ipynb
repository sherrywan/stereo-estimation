{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data0/wxy/anaconda3/envs/py37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 161362\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.join(\"/data0/wxy/3d_pose/stereo-estimation/\"))\n",
    "from lib.dataset.human36m import Human36MMultiViewDataset\n",
    "\n",
    "\n",
    "h36m_root = os.path.join(\"/data1/share/dataset/human36m_multi-view/\", \"processed\")\n",
    "labels_stereo_npy_path = \"/data1/share/dataset/human36m_multi-view/extra/human36m-stereo-labels-GTbboxes.npy\"\n",
    "\n",
    "dataset = Human36MMultiViewDataset(\n",
    "    h36m_root,\n",
    "    labels_stereo_npy_path,\n",
    "    train=True,                       # include all possible data\n",
    "    test=True,\n",
    "    image_shape=None,                 # don't resize\n",
    "    retain_every_n_frames_in_test=1,  # yes actually ALL possible data\n",
    "    with_damaged_actions=True,        # I said ALL DATA\n",
    "    kind=\"mpii\",\n",
    "    norm_image=False,                 # don't do unnecessary image processing\n",
    "    undistort_images=True,                 \n",
    "    crop=True)                       # don't crop\n",
    "print(\"Dataset length:\", len(dataset))\n",
    "\n",
    "def test_rectificate(idx):\n",
    "    sample = dataset[idx]\n",
    "    \n",
    "    shot = dataset.labels['table'][idx]\n",
    "    subject_idx = shot['subject_idx']\n",
    "    action_idx  = shot['action_idx']\n",
    "    frame_idx   = shot['frame_idx']\n",
    "\n",
    "    subject = dataset.labels['subject_names'][subject_idx]\n",
    "    action = dataset.labels['action_names'][action_idx]\n",
    "\n",
    "    available_cameras = list(range(len(dataset.labels['action_names'])))\n",
    "    \n",
    "    for camera_idx, bbox in enumerate(shot['bbox_by_camera_tlbr']):\n",
    "        if bbox[2] == bbox[0]: # bbox is empty, which means that this camera is missing\n",
    "            available_cameras.remove(camera_idx)\n",
    "    \n",
    "    for camera_idx, image, keypoit_2d in zip(available_cameras, sample['images'], sample['keypoints_2d']):\n",
    "        camera_name = dataset.labels['camera_names'][camera_idx]\n",
    "\n",
    "        output_image_folder = os.path.join(camera_name)\n",
    "        output_image_path = os.path.join(output_image_folder, 'img_%06d.png' % (idx+1))\n",
    "        os.makedirs(output_image_folder, exist_ok=True)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(image)\n",
    "        plt.scatter(keypoit_2d[:, 0], keypoit_2d[:, 1], s=1, c='red')\n",
    "        plt.savefig(output_image_path)\n",
    "        plt.close()\n",
    "\n",
    "for idx in range(0, 160000, 5000):\n",
    "    test_rectificate(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('py37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b729c18568aaef96e75e69aa5c039e7cab15308562f915d58a4137142307f7cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
